---
title: "Supervised Learning - Support Vector Machines"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(dev = 'svg')
options(device = function(file, width, height) {
  svg(tempfile(), width = width, height =height)
})
```

Another juggernaught of supervised learning techniques is the support vector machine (SVM). SVMs essentially try and find boundaries, or hyperplanes, that best separate our data into groups ([Wikipedia][1]). Let's try to visualize this separation ([towards data science][2]):

![svm](images/svm.PNG)

Here we can better see that a SVM is separating data points based on the best possible hyperplane. But sometimes that best hyperplane isn't in a simple x vs. y plot. We might need a higher dimensional plot to accomplish that separation (i.e. so xyz instead of just xy as an example). To avoid calculating out all the possible dimensions we can use **kernels** to make our feature space larger and accommodate non-linear patterns ([towards data science][2]). So let's try it out!

```{r svm.setup,message=F,warning=F}
load("lgg.rda")
library(kernlab)
library(e1071)
library(limma)
#we are going to do something different here and use our gene expression data
#let's first filter, normalize and grab only the top 100 genes with the
#highest variance
filt.exp <- lgg$ExpressionData[rowMeans(lgg$ExpressionData)>10,]
log_trans <- log2(filt.exp+1)
norm_data <- normalizeQuantiles(log_trans)
vars <- rank(-apply(norm_data,1,var))<=50
#here we make sure our predictor variables are the columns
df <- as.data.frame(t(norm_data[vars,]))
#let's remove those pesky special characters from the gene names
colnames(df) <- gsub("-","",gsub("\\|.*","",colnames(df)))

#now let's try to predict IDH1 mutant status
df$idh1_mutant_status <- as.factor(as.numeric(
  gsub(
  "WT","0",
  gsub(
    "Mutant","1",
    as.character(lgg$PatientData$paper_IDH.status)
    ))))
df$idh1_mutant <- as.character(lgg$PatientData$paper_IDH.status)
df <- na.omit(df)
```

Here we employ the same procedure in the neural network topic note to isolate the top 50 genes with the highest variance. We will use these genes to predict IDH1 mutant status!

```{r svm,message=F,warning=F}
library(GGally)
#split data into training and test data
set.seed(42)
train_ind <- sample(1:nrow(df), 0.8*nrow(df))
train <- df[train_ind, ]
test  <- df[-train_ind, ]
#now let's make our model!
svmfit <- svm(train[,51]~., data = train[,1:50], kernel = "radial", gamma = 1, cost = 1)
# justify our support vector machine
ggpairs(train, columns = 1:5, ggplot2::aes(colour=idh1_mutant))
```

Here we build our support vector machine off the genes with the top 10 highest variance. Notice that we use a radial kernel with a ```cost``` of 1 and a ```gamma``` value of 1. These terms are adjustable to create a better model, but we will get to that in a minute. We also used the ```GGally``` library to plot the correlation between our variables and how they separate by IDH1 mutant status. For now it is important to see that our data isn't easily separable using two dimensions, which is why we used the kernel function to better draw that separating hyperplane. But let's see if we can improve upon this.

```{r svm.improve, message=FALSE,warning=FALSE}
library(caret)
#let's find our best gamma/cost values
tuning <- tune.svm(idh1_mutant_status~., data = train[,1:51] , gamma = 10^(-6:-1) , cost=10^(-1:3))
#now let's predict!
svm_cm <- confusionMatrix(
  table(
    actual=test$idh1_mutant_status,
    predicted = predict(tuning$best.model,newdata=test[,1:51])
  )
)
c(svm_cm$overall["Accuracy"],
svm_cm$byClass["Sensitivity"],
svm_cm$byClass["Specificity"])
#define our function to get class error
ClassError = function(actual, predicted) {
  mean(actual != predicted)
}
ClassError(actual=train$idh1_mutant_status,
           predicted = predict(tuning$best.model,data=train[,1:51]))
ClassError(actual=test$idh1_mutant_status,
           predicted = predict(tuning$best.model,data=test[,1:51]))
```

Here we can see that our model seems to be performing quite well with an accuracy, specificity, and sensitivity of 100%. However, calculating the classification error shows how overfit this model is. 

## References

1. https://en.wikipedia.org/wiki/Support-vector_machine

2. https://towardsdatascience.com/svm-feature-selection-and-kernels-840781cc1a6c

[1]: https://en.wikipedia.org/wiki/Support-vector_machine

[2]: https://towardsdatascience.com/svm-feature-selection-and-kernels-840781cc1a6c